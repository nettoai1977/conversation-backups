"""
Integration Test Suite for OpenClaw Multi-Agent Systems & Integration Tools
Tests the complete implementation of research findings
"""

import asyncio
import json
from datetime import datetime
import subprocess
import sys
import os
from pathlib import Path

# Add project root to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from skills.enhanced_skills import EnhancedSkillsRegistry
from skills.skills_marketplace import SkillMarketplace, SkillsOrchestrationEngine
from multi_agent_system.orchestrator_worker import MultiAgentSystem
from cli_tools.python_cli_tool import OpenClawCLITool
from cli_tools.n8n_integration import N8nWorkflowManager

async def test_skills_system():
    """Test the enhanced skills system"""
    print("ğŸ§ª Testing Skills System...")
    
    # Test enhanced skills registry
    registry = EnhancedSkillsRegistry.get_instance()
    print(f"   âœ“ Enhanced Skills Registry initialized with {len(registry.get_all_skills())} skills")
    
    # Test skill execution
    skills = registry.get_all_skills()
    if skills:
        first_skill_name = list(skills.keys())[0]
        result = await skills[first_skill_name].execute()
        print(f"   âœ“ Skill '{first_skill_name}' executed: {result.get('success', 'Unknown')}")
    
    # Test performance metrics
    if skills:
        first_skill = list(skills.values())[0]
        metrics = first_skill.get_performance_metrics()
        print(f"   âœ“ Performance metrics retrieved: {metrics}")
    
    print("   âœ… Skills System tests passed\n")

async def test_skills_marketplace():
    """Test the skills marketplace and orchestration"""
    print("ğŸ§ª Testing Skills Marketplace...")
    
    # Initialize marketplace
    marketplace = SkillMarketplace("./test_marketplace")
    print("   âœ“ Skills Marketplace initialized")
    
    # Publish a test skill
    skill_id = await marketplace.publish_skill(
        name="Test Skill",
        description="A test skill for integration testing",
        category="testing",
        code="def test_function(): return {'result': 'success'}",
        schema={"input": {}, "output": {"result": "string"}},
        documentation="Test skill documentation"
    )
    print(f"   âœ“ Test skill published with ID: {skill_id}")
    
    # Search for skills
    search_results = await marketplace.search_skills(query="test")
    print(f"   âœ“ Search returned {len(search_results)} results")
    
    # Add a review
    await marketplace.add_review(skill_id, "test_user", 5, "Great test skill!")
    print("   âœ“ Review added to test skill")
    
    # Initialize orchestration engine
    engine = SkillsOrchestrationEngine(marketplace)
    print("   âœ“ Orchestration Engine initialized")
    
    # Compose a workflow
    workflow_id = await engine.compose_workflow(
        name="Test Workflow",
        description="A test workflow for integration",
        skill_chain=[{"skill_id": skill_id, "parameters": {}}]
    )
    print(f"   âœ“ Workflow composed with ID: {workflow_id}")
    
    # Execute workflow
    execution_result = await engine.execute_workflow(workflow_id, {})
    print(f"   âœ“ Workflow executed: Success = {execution_result.get('success', 'Unknown')}")
    
    # Get performance metrics
    perf_metrics = await engine.get_workflow_performance(workflow_id)
    print(f"   âœ“ Performance metrics retrieved: {perf_metrics}")
    
    print("   âœ… Skills Marketplace tests passed\n")

async def test_multi_agent_system():
    """Test the multi-agent system"""
    print("ğŸ§ª Testing Multi-Agent System...")
    
    # Initialize multi-agent system
    mas = MultiAgentSystem()
    orchestrator = mas.setup_orchestrator()
    print("   âœ“ Multi-Agent System initialized with orchestrator")
    
    # Define test executors
    async def test_executor(task_desc):
        await asyncio.sleep(0.1)  # Simulate work
        return f"Completed: {task_desc}"
    
    # Add worker agents
    worker1 = mas.add_worker_agent("worker_1", ["test"], test_executor)
    worker2 = mas.add_worker_agent("worker_2", ["test"], test_executor)
    print(f"   âœ“ Added 2 worker agents")
    
    # Submit tasks
    result1 = await mas.submit_task("Test task 1", priority=2)
    result2 = await mas.submit_task("Test task 2", priority=1)
    print(f"   âœ“ Submitted 2 tasks, results: {result1.get('success')} & {result2.get('success')}")
    
    # Check agent status
    status = mas.get_agent_status()
    print(f"   âœ“ Agent status retrieved: {len(status)} agents")
    
    print("   âœ… Multi-Agent System tests passed\n")

def test_cli_tools():
    """Test CLI tools integration"""
    print("ğŸ§ª Testing CLI Tools...")
    
    # Test CLI tool initialization
    cli_tool = OpenClawCLITool()
    print("   âœ“ Enhanced CLI Tool initialized")
    
    # Test system stats
    stats_result = cli_tool.get_system_stats()
    print(f"   âœ“ System stats retrieved: {stats_result.get('success')}")
    
    # Test file search
    search_result = cli_tool.search_files(".", "*.py", False)
    print(f"   âœ“ File search executed: {search_result.get('success')}, found {search_result.get('count', 0)} files")
    
    print("   âœ… CLI Tools tests passed\n")

def test_configuration_files():
    """Test that configuration files were created properly"""
    print("ğŸ§ª Testing Configuration Files...")
    
    # Check MCP server configuration
    config_path = Path("config/mcp_servers_config.json")
    if config_path.exists():
        with open(config_path, 'r') as f:
            config = json.load(f)
        print(f"   âœ“ MCP server config found with {len(config)} servers")
    else:
        print("   âœ— MCP server config not found")
    
    # Check startup script
    startup_script = Path("scripts/start_mcp_servers.sh")
    if startup_script.exists():
        print("   âœ“ Startup script found")
    else:
        print("   âœ— Startup script not found")
    
    # Check test script
    test_script = Path("scripts/test_mcp_servers.py")
    if test_script.exists():
        print("   âœ“ Test script found")
    else:
        print("   âœ— Test script not found")
    
    print("   âœ… Configuration tests passed\n")

async def test_complete_integration():
    """Test complete integration of all components"""
    print("ğŸ§ª Testing Complete Integration...")
    
    # Test that all major components can work together
    registry = EnhancedSkillsRegistry.get_instance()
    marketplace = SkillMarketplace("./integration_test_marketplace")
    mas = MultiAgentSystem()
    
    # Create a skill in marketplace
    skill_id = await marketplace.publish_skill(
        name="Integration Test Skill",
        description="Skill for complete integration test",
        category="integration",
        code="def integration_test(): return {'status': 'integrated', 'timestamp': 'now'}",
        schema={"input": {}, "output": {"status": "string", "timestamp": "string"}}
    )
    
    # Create a workflow using the skill
    engine = SkillsOrchestrationEngine(marketplace)
    workflow_id = await engine.compose_workflow(
        name="Integration Test Workflow",
        description="Workflow for complete integration test",
        skill_chain=[{"skill_id": skill_id, "parameters": {}}]
    )
    
    # Execute the workflow
    execution_result = await engine.execute_workflow(workflow_id, {})
    
    print(f"   âœ“ Complete integration test executed: Success = {execution_result.get('success')}")
    
    # Test that the orchestrator can potentially use skills
    mas.setup_orchestrator()
    
    print("   âœ… Complete Integration tests passed\n")

async def run_all_tests():
    """Run all integration tests"""
    print("ğŸš€ Starting OpenClaw Integration Tests\n")
    print("="*60)
    
    start_time = datetime.now()
    
    try:
        await test_skills_system()
        await test_skills_marketplace()
        await test_multi_agent_system()
        test_cli_tools()
        test_configuration_files()
        await test_complete_integration()
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        print("="*60)
        print(f"ğŸ‰ All Integration Tests PASSED!")
        print(f"â±ï¸  Total Duration: {duration}")
        print(f"âœ… Implementation is working correctly")
        
        # Summary of what was tested
        print("\nğŸ“‹ Tested Components:")
        print("   â€¢ Enhanced Skills System (with validation, performance metrics)")
        print("   â€¢ Skills Marketplace (publishing, searching, reviews)")
        print("   â€¢ Skills Orchestration Engine (workflow composition, execution)")
        print("   â€¢ Multi-Agent System (orchestrator-worker pattern)")
        print("   â€¢ Enhanced CLI Tools (security, monitoring, execution)")
        print("   â€¢ Configuration Files and Scripts")
        print("   â€¢ Complete Integration (all components working together)")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Integration Test FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(run_all_tests())
    sys.exit(0 if success else 1)